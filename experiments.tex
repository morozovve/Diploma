
\subsection{Экспериментальная часть}
\label{sec:experiments}
Для экспериментальной оценки реализации предложенного решения мы использовали набор данных GTD\_0616 \cite{db:gtd}.
% GTD description
Этот набор данных обладает следующими особенностями:
	\begin{enumerate}
		\item Содержит подробную информацию о терактах начиная с 1975 года
		\item Содержит 55'600 записей с 1991 по 2012 год
        \item Информация включает в себя подробное описание теракта: дата, страна, группировка, ущерб, ...
        \item Содержит разнородные признаки: количественные, категориальные и, для некоторых событий, текстовые описания.
	\end{enumerate}

% Data aggregation using NMF model
\subsubsection{Построение представления событий и интерпретируемость}
Чтобы получить необходимое нам представление событий в пространстве тематик, были использованы алгоритм матричной факторизации NMF и нейросетевой подход, основанный на автокодировщиках.
После преобразований, описанных в начале раздела \ref{subsub:repr} и агрегирования мы перешли от отдельных событий к \textit{временному периоду}, содержащему некоторые события с помощью усреднения значений тематик для событий, входящих в этот период. Далее будем называть этот период \textit{агрегационным периодом} или просто \textit{периодом}. Затем к предобработанным данным мы применяли методы построения представления событий, пример 10 выделенных тематик как результат работы алгоритма неотрицательной факторизации матриц можно видеть на  Рис. \ref{fig:features_example}.

\begin{figure}
  \includegraphics[width=\linewidth]{features_example.png}
  \caption{Пример временных рядов для тематик NMF}
  \label{fig:features_example}
\end{figure}

В случае с нейросетевым автокодировщиком, использовалась архитектура, описанная в таблице \ref{table:ae_arch}. Для кодировщика последовательно использовались полносвязные слои размерностей 256, 128 и 50 (размерность кода). Для декодировщика использовались полносвязные слои тех же размерностей, но в обратном порядке. Размерность входного вектора была равна 414, в рамках экспериментов были исследованы размерности скрытого кода равные 10 и 50. Для обучения модели применялась функция потерь $MAE$, описанная выше.
Количество эпох (т.е. количество проходов по всем имеющимся данным) при обучение модели было выбрано равным 100, начальный темп обучения был выбран равным  $2\cdot 10^{-3}$, также было использование экспоненциальное затухание темпа обучения: после каждой эпохи величина темпа обучения умножалась на 0.96.

\begin{table}
\centering
 \begin{tabular}{| c | c | c | c |} 
 \hline
 Название слоя & Тип слоя & Размер входа & Размер выхода \\
 \hline
 \hline
 кодировщик(1) & Полносвязный & 414 & 256 \\ 
 \hline
 кодировщик(2) & Полносвязный & 256 & 128 \\ 
 \hline
 кодировщик(3) & Полносвязный & 128 & 50 \\ 
 \hline
 декодировщик(1) & Полносвязный & 50 & 128 \\ 
 \hline
 декодировщик(2) & Полносвязный & 128 & 256 \\ 
 \hline
 декодировщик(3) & Полносвязный & 256 & 414 \\ 
 \hline
\end{tabular}
\caption{Архитектура автокодировщика}
\label{table:ae_arch}
\end{table}

Для интерпретации тематик методом, описанным в \ref{subsub:interp}, из набора данных были извлечены 19335 событий с текстовыми описаниями. После предобработки описаний и выделения слов был получен словарь размера 2311. После применения всей процедуры, описанной в \ref{subsub:interp} были получены наборы ключевых слов, описывающие тематики. Примеры таких ключевых слов для первых 5 тематик указаны в таблице \ref{table:kw_example}.

\begin{table}
\centering
 \begin{tabular}{c c} 
 \hline
 Тематика & Ключевые слова\\ 
 \hline
 \hline
 0 & used, sources, available, majority, listed, database, ...\\
 \hline
 1 & shot, civilian, distributed, bomb, detonated, ...\\
 \hline
 2 & taliban, shrine, perpetrators, tamil, rebels, group, ...\\
 \hline
 3 & released, hostage, kidnapping, status, abduction, ...\\
 \hline
 4 & indicated, military, police, civilian, detonating, ...\\
 \hline
 \end{tabular}
\caption{Примеры ключевых слов из описаний тематик }
\label{table:kw_example}
\end{table}


\subsubsection{Описание процесса обучения и тестирования} \label{train_process}
% NMF topics with lags as features
Метод прогнозирования, описываемый в моей работе, основывается на предположении, что вероятность наступления события (или количество событий) зависит от предшествующих событий, а точнее от значений тематик в агрегационных периодах, предшествующих периоду, для которого мы предсказываем эту вероятность.
В качестве признаков использовались значения тематик из $L$ предшествующих периодов, и таким образом для $k$ тематик размерность итогового пространства признаков становилась равна $L \cdot k$.

% target generation
Чтобы сформировать \textit{целевую переменную} необходимо было сначала определить события, которые нас интересуют (далее - \textit{целевые события}), в этой работе такие события определены как теракты, произошедшие в Ираке с типом атаки "взрыв". Затем каждому событию ставилась в соответствие метка: 1, если это интересующее нас событие и 0 иначе. 

Поскольку данные имеют очевидную временную составляющую, то разбиение на \textit{тренировочную} и \textit{тестовую} выборку производилось строго последовательно: первые 70\% данных отводились для тренировочной выборки, а оставшиеся 30\% - для тестовой.

% Metrics: ROC AUC, MAE
Для оценки качества решения в задаче классификации использовалась метрика ROC AUC, как уже было сказано выше, одно из ее преимуществ заключается в том, что она инвариантна к несбалансированности классов (в отличие, например, от метрики "Точность"). Поскольку в задачах прогнозирования событий реальные данные редко бывают сбалансированы, применение этой метрики является более разумным выбором для отражения качества прогноза.

В задаче регрессии для оценки решения была выбрана метрика MASE, которая рассчитывается по формуле, описанной в \ref{sect:event_forecast}.

% \subsection{Выбор разбиения данных} 
% \textit{Разбиение данных} - набор величин (год начала, год конца, длина периода агрегации, размер тренировочной выборки и правила для выбора целевых событий), характеризующий данные, получаемые после агрегации и генерации целевой переменной.\par
% % Automated time period choosing, different stats calculations
% Выше были определены признаки, которые будут использоваться для решения поставленных задач, и была упомянута проблема несбалансированных данных.
% На самом деле, если взять произвольные правила для определения целевого события (напр: страна Пакистан, тип атаки: Похищение) может оказаться, что ни один агрегационный период не содержит таких событий. Решение таких задач относится к области "прогнозирование экстремально редких событий (extreme rare event prediction) и выходит за рамки этой работы. 
% Чтобы избежать подобного дисбаланса было решено перебрать некоторое количество параметров, характеризующих данные, таких как
% \begin{enumerate}
%     \item Начальный и конечный год: 1997-2004 и 2004-2008 соответственно. Данные до начального и после конечного года мы не используем.
%     \item Длина периода агрегации: 1-15 дней, чем меньше, тем меньше значения целевой переменной.
%     \item Размер тренировочной выборки: 70\%, 80\%
%     \item Правила для выбора целевых событий: различные сочетания стран (Ирак/Пакистан/...) и типов атаки (Взрыв/Вооруженное нападение/...)
% \end{enumerate}
% В итоге была сформирована таблица, показывающая более-менее сбалансированные разбиения данных.

% Чтобы разбиение попало в таблицу, оно должно удовлетворять некоторым правилам.
% Для задачи классификации введем следующие обозначения:
% $\alpha := 0.1$,
% $r := 0.3$,
% $N_{train} := 300$,
% Обозначим долю положительных меток тренировочной и тестовой выборки как $Tr_m$ и $Ts_m$ соответственно, а размер тренировочной выборки как $Tr_{size}$.
% Тогда правила для разбиения выглядят следующим образом:
% \begin{itemize}
%     \item $Tr_m, Ts_m \in (\alpha, 1-\alpha$ (чтобы избежать дисбаланса классов в данных в целом)
%     \item $\frac{Tr_m}{Tr_m + Ts_m} \in (r, 1-r)$ (чтобы избежать дисбаланса между тренировочной и тестовой выборкой)
%     \item $Tr_{size} > N_{train}$ (чтобы было достаточно данных для обучения)
% \end{itemize}
% Для задачи регрессии введем дополнительно $r_{max} := 3$ и определим правила разбиения следующим образом:
% \begin{itemize}
%     \item $Ts_m > 0$
%     \item $\frac{Tr_m}{Ts_m}\in(1/r_{max}, r_{max})$ (избегаем дисбаланса между тренировочной и тестовой выборкой)
%     \item $Tr_{size} > N_{train}$ (чтобы было достаточно данных для обучения)
% \end{itemize}

% \begin{figure}
%   \includegraphics[width=\linewidth]{split_example.png}
%   \caption{Пример найденных разбиений для исходного набора данных}
%   \label{fig:split_example}
% \end{figure}

\subsubsection{Использование текстовых данных} \label{lda_topics}
% LDA model and document merging over agg period
В дополнение к существующим исходным признакам было решено использовать текстовые описания событий, а точнее соответствующие им вектора признаков, полученные с помощью модели Латентного размещения Дирихле (LDA) \cite{lda_orig}.
 
Модель Латентного размещения Дирихле представляет из себя статистическую модель, используемую в основном в задачах обработки текстов. Эта модель работает с документами, которые в свою очередь являются последовательностью термов (слов). Для заранее заданного числа скрытых (латентных) тем LDA позволяет построить два распределение: распределения тем по документам и распределения термов по темам. После того как модель обучена на $N$ документах для количества тем равного $K$ и количества различных термов равного $V$, мы получаем две матрицы весов $\theta \in \mathbf{R}^{N \times K}$ и $\phi \in \mathbf{R}^{K \times V}$, характеризующие параметры распределения Дирихле. Матрица $\theta$ отражает распределение тем по документам, а матрица $\phi$ -- распределение термов по темам.

Для получения значений скрытых тем новых документов необходимо их так же предобработать так же, как и тексты на которых производилось обучение, а затем, используя матрицу $\phi$ получить значения скрытых тем из текстового содержания документа.
После извлечения тематик каждому документу в соответствие ставится числовой вектор размерности $K$.

В рамках экспериментов алгоритм использования текстовых признаков с помощью модель Латентного размещения Дирихле выглядит следующим образом:
\begin{enumerate}
    \item Для каждого агрегационного периода получить единственный текстовый документ путем конкатенации (склеивания) всех текстовых описаний событий, входящих в период.
    \item Произвести классическую предобработку этих документов: удалить пунктуацию, нормализовать слов, удалить стоп-слова, ....
    \item Используя эти документы (точнее ту их часть, которая относится к тренировочной выборке) построить LDA-модель, т.е. построить распределение тематик по документам и распределение слов по тематикам для заданного количества тематик (в экспериментах количество тематик берется равным 10)
    \item Используя модель из предыдущего пункта получить 10 дополнительных признаков (соответствующих текстовым тематикам) для каждого агрегационного периода и использовать их вместе (с помощью конкатенации) с признаками, соответствующими скрытому представлению.
\end{enumerate}

Пример пяти тематик (их ключевых слов), выделенных с помощью LDA:
\begin{enumerate}
    \item incid bomb kill total relat
    \item claim respons group region kill
    \item group respons claim bomb injur
    \item incid target algerian take place
    \item algerian take place forc kill
\end{enumerate}

\begin{figure}
  \includegraphics[width=\linewidth]{lda_example.png}
  \caption{Пример временных рядов для тематик LDA}
  \label{fig:lda_example}
\end{figure}

Пример соответствующих временных рядов можно увидеть на Рис. \ref{fig:lda_example}

\subsubsection{Результаты}
% Ниже приведены результаты для различных вариантов эксперимента.
Условия эксперимента:
\begin{enumerate}
    \item Год начала - 2002
    \item Год конца - 2008
    \item Длина агрегационного периода - 3 дня
    \item Тренировочная выборка: 70\%
    \item Целевые события: взрывы в Ираке (страна = Iraq, тип атаки = Bombing/Explosion)
\end{enumerate}
В рамках эксперимента были исследованы различные варианты представления событий -- с помощью NMF и с использованием автокодировщиков; количество тематик в экспериментах -- 10 и 50, так же вместе с тематиками были использованы дополнительные признаки AUX и REC.
В качестве моделей для прогнозирования были использованы классические модели классификации Logistic Regression (LogReg) и Random Forest Classifier (RFC), а так же нейронная сеть архитектуры LSTM.
Для задачи регрессии использовались модели Linear Regression (LinReg), Random Forest Regressor (RFR), а так же нейронная сеть архитектуры LSTM. Также варьировался размер окна исторических данных, которое мы принимали во внимание для построения прогноза. В текущем эксперименте были рассмотрены размеры окна равные 10 и 30.

В рамках экспериментов использовалась следующая архитектура сети LSTM: длина входной последовательности была равна 10 и 30 в зависимости от эксперимента и совпадала с размером окна исторических данных. Размерность скрытого слоя состояния LSTM-блока была равна размерности скрытого представления $k$ и принимала значения равные 10 и 50. При решении задачи прогнозирования вероятности события мы использовали функцию softmax для преобразования выхода сети в вероятности. В случае прогнозирования количества событий мы использовали линейную функцию активации. В процессе тренировки нейронной сети темп обучения был выбран равным $10^{-3}$, а количество эпох равным 50.

Обозначения:
\begin{itemize}
    \item  NMF\_N / AE\_N - использование тематик полученных с помощью NMF / Автокодировшика и с использованием N тематик
    \item + A - использование 2 дополнительных признаков (AUX), добавляющих авторегрессионную составляющую и описанных в \ref{train_process}
    \item + R - использование дополнительного признака, отвечающего за ошибку восстановления (реконструкции) в автокодировщике и описанного в \ref{train_process}
    %\item + text - использование 10 дополнительных тематик, описанных в \ref{lda_topics}
\end{itemize}

Перед изучением непосредственно результатов, важно отметить способ которым выбирались значения гиперпараметров для экспериментов. Пропорции разбиения данных на тренировочную и тестовую были выбраны как 70 к 30, поскольку это,  классический и наиболее часто используемый способ разбиения данных. Вторая причина выбора такого разбиения в том, что это позволяет оставить в тренировочном наборе достаточно данных для адекватного обучения модели и в то же время тестовый набор содержит в не слишком мало данных для валидации (тестирования). 

Длина агрегационного периода равная 3 дням была выбрана эмпирически, исходя из распределения целевой переменной. В общем случае длина интервала должна подбираться для каждой задачи отдельно, исходя из здравого смысла и поставленных целей. Так, например, если события редкие, то имеет смысл увеличить длину агрегационного периода. В случае если, например, стоит задача прогнозирования и изучения событий с недельной сезонностью, имеет смысл взять период агрегации равным 7 дням. 

Значения остальных гиперпараметров подбирались эмпирически. Поскольку основной целью данной работы является не получение максимальной точности на какой-то конкретной задаче, а описание и исследование применимости нового подхода к решению целого класса задач, тщательный перебор гиперпараметров не производился. Вероятнее всего, перебрав тщательным образом такие гиперпараметры как, например, число тематик и количество используемых исторических данных, можно значительно повысить итоговую точность прогнозирования.

\subsubsection{Прогнозирование вероятности события}
Поскольку задача прогнозирования вероятности события сводится к задаче классификации и определения, произойдет событие или нет, для решения этой задачи были выбраны модели классификации.
В таблицах \ref{table:clf-res-no-text} и \ref{table:clf-res-text} представлены результаты решения задачи по метрике ROC AUC (чем меньше, тем лучше) для различных моделей и условий тестирования. Лучшие из обученных моделей смогли достигнуть ROC AUC $\approx$ 0.75-0.79. Лучшие результаты получали модели прогнозирования LSTM для всех трех вариантов извлечения этих тематик (матричная факторизация, автокодировщик, автокодировщик + ошибка восстановления). Также можно увидеть, что вспомогательные признаки (AUX) помогли моделям достигать более качественных результатов. Что касается размера окна (кол-ва исторических данных, использовавшихся для прогнозирования), то в среднем модели LSTM достаточно хорошо работали для размеров окна равных 10 и 30, в то время как классические модели (Random Forest Classifier, Logistic Regression) показывали более хорошие результаты на меньшем размере окна. Это может быть связанно с тем, что количество признаков при увеличении размера окна росло линейно и моделям было сложнее найти нужные паттерны в данных.
При использовании текстовых описаний модели LSTM показали как результатов, причем независимо от метода построения представления событий. Модели логистической регрессии и случайного леса на некоторых методах представления событий показали выигрыш по качеству с добавлением текстовых описаний, а на других стали работать немного хуже. Это, опять же, можно объяснить меньшей гибкостью линейных моделей и модели случайного леса.

\begin{table}
\centering
\begin{tabular}{||p{3.8cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}||} 
\hline
& LSTM L=10 & LSTM L=30 & LogReg L=10 & LogReg L=30 & RFC L=10 & RFC L=30\\ \hline\hline
AE10 & 0.616 & 0.641 & 0.439 & 0.417 & 0.484 & 0.509\\ \hline
AE10+A & 0.747 & 0.749 & 0.654 & 0.578 & 0.583 & 0.598\\ \hline
AE50 & 0.651 & 0.655 & 0.567 & 0.574 & 0.656 & 0.637\\ \hline
AE50+A & 0.743 & 0.752 & 0.655 & 0.552 & 0.658 & 0.578\\ \hline
AE10+R & 0.696 & 0.656 & 0.480 & 0.608 & 0.509 & 0.566\\ \hline
AE10+AR & 0.764 & 0.744 & 0.653 & 0.572 & 0.609 & 0.615\\ \hline
AE50+R & 0.547 & 0.544 & 0.605 & 0.588 & 0.443 & 0.623\\ \hline
AE50+AR & 0.761 & 0.760 & 0.655 & 0.551 & 0.659 & 0.606\\ \hline
NMF10 & 0.618 & 0.605 & 0.577 & 0.526 & 0.637 & 0.606\\ \hline
NMF10+A & 0.746 & 0.746 & 0.653 & 0.561 & 0.701 & 0.670\\ \hline
NMF50 & 0.691 & 0.711 & 0.537 & 0.446 & 0.650 & 0.533\\ \hline
NMF50+A & 0.740 & \textbf{0.783} & 0.658 & 0.580 & 0.638 & 0.671\\ \hline
 \end{tabular}

\caption{\label{table:clf-res-text} Результаты по метрике ROC AUC для задачи классификации без использования текста}
\label{table:clf_res-no-text}
\end{table}


\begin{table}
\centering
\begin{tabular}{||p{3.8cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}||} 
\hline
& LSTM L=10 & LSTM L=30 & LogReg L=10 & LogReg L=30 & RFC L=10 & RFC L=30\\ \hline\hline
AE10 & 0.597 & 0.657 & 0.505 & 0.563 & 0.679 & 0.361\\ \hline
AE10+A & 0.764 & 0.747 & 0.642 & 0.599 & 0.673 & 0.665\\ \hline
AE50 & 0.655 & 0.678 & 0.523 & 0.550 & 0.624 & 0.631\\ \hline
AE50+A & 0.752 & 0.745 & 0.645 & 0.493 & 0.681 & 0.614\\ \hline
AE10+R & 0.608 & 0.628 & 0.523 & 0.564 & 0.424 & 0.474\\ \hline
AE10+AR & \textbf{0.795} & 0.758 & 0.642 & 0.576 & 0.644 & 0.619\\ \hline
AE50+R & 0.505 & 0.553 & 0.523 & 0.552 & 0.575 & 0.616\\ \hline
AE50+AR & 0.736 & 0.759 & 0.644 & 0.523 & 0.674 & 0.504\\ \hline
NMF10 & 0.612 & 0.743 & 0.476 & 0.563 & 0.652 & 0.615\\ \hline
NMF10+A & 0.601 & 0.753 & 0.644 & 0.544 & 0.674 & 0.567\\ \hline
NMF50 & 0.776 & 0.688 & 0.484 & 0.547 & 0.575 & 0.498\\ \hline
NMF50+A & 0.741 & 0.753 & 0.645 & 0.569 & 0.688 & 0.625\\ \hline
 \end{tabular}
\caption{\label{table:clf-res-no-text} Результаты по метрике ROC AUC для задачи классификации с использованием текста}
\label{table:clf_res-text}
\end{table}

\begin{figure}
  \includegraphics[width=\linewidth]{rf_clf_example.png}
  \caption{Пример работы модели классификации}
  \label{fig:rf_clf_example}
\end{figure}

\subsubsection{Прогнозирование количества событий}
Задача прогнозирования количества событий является задачей регрессии и может быть решена соответствующими моделями. В рамках экспериментов были рассмотрены модели линейной регрессии, случайного леса и нейросетевая модель архитектуры LSTM.
В таблицах \ref{table:reg-res-no-text}, \ref{table:reg-res} \ref{table:reg-res-no-text-log} и \ref{table:reg-res-log} представлены результаты решения задачи регрессии по метрике MASE (чем меньше, тем лучше) для различных моделей и условий тестирования.

Как было сказано в \ref{sect:event_forecast}, мы будем прогнозировать не целевую переменную, а ее логарифм. Поскольку для восстановления исходного значения целевой переменной требуется отложенная (валидационная) выборка для подсчета ошибки, разбиение данных в экспериментах будет производиться в пропорции 0.7 (тренировочная выборка) + 0.1 (валидационная) + 0.2 (тестовая). Таблицы \ref{table:reg-res-no-text} и \ref{table:reg-res} приведены для сравнения результатов с использованием и без использования логарифмического преобразования.

Лучшие из обученных моделей смогли достигнуть MASE $\approx$ 0.83-0.84. Лучшие результаты получали модели прогнозирования RFR, вспомогательные признаки (AUX) снова помогли моделям достигать более качественных результатов. Лучшим методом извлечения скрытых тематик оказался метод, основанный на автокодировщиках. В таблицах \ref{table:reg-res-no-text-log} и \ref{table:reg-res-log} видно, что значения метрики MASE для модели LinReg иногда становятся $\gg 1$. Это связанно с тем, что модель линейной регрессии показывает неудовлетворительные результаты на валидационной выборке. И, поскольку при восстановлении истинного значения целевой переменной используется среднеквадратичная ошибка по валидационной выборке, как описано в \ref{subsub:forecasting}, результаты модели оказываются сильно смещенными, вызывая аномально большие значения ошибки на тестовой выборке.

\begin{table}
\centering
\begin{tabular}{||p{3.8cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}||} 
\hline
& LSTM L=10 & LSTM L=30 & LinReg L=10 & LinReg L=30 & RFR L=10 & RFR L=30\\ \hline\hline
AE10 & 1.218 & 1.204 & 1.119 & 1.191 & 1.241 & 1.265\\ \hline
AE10+A & 1.050 & 1.050 & 0.909 & 1.074 & 0.890 & 0.909\\ \hline
AE10+R & 1.092 & 1.096 & 1.121 & 1.193 & 1.239 & 1.287\\ \hline
AE10+AR & 1.054 & 1.072 & 0.911 & 1.102 & 0.886 & 0.910\\ \hline
AE50 & 1.119 & 1.155 & 1.180 & 1.657 & 1.244 & 1.257\\ \hline
AE50+A & 1.084 & 1.055 & 1.632 & 1.616 & 0.883 & 0.904\\ \hline
AE50+R & 1.040 & 1.039 & 1.209 & 1.580 & 1.243 & 1.278\\ \hline
AE50+AR & 1.059 & 1.056 & 1.632 & 1.758 & \textbf{0.876} & 0.916\\ \hline
NMF10 & 1.218 & 1.194 & 1.096 & 1.422 & 1.094 & 1.182\\ \hline
NMF10+A & 1.056 & 1.069 & 0.895 & 1.177 & 0.894 & 0.929\\ \hline
NMF50 & 1.136 & 1.128 & 1.336 & 1.112 & 1.092 & 1.155\\ \hline
NMF50+A & 1.076 & 1.061 & 1.468 & 1.181 & 0.913 & 0.912\\ \hline
\end{tabular}
\caption{Результаты по метрике MASE для задачи регрессии без использования текста и без использования лог-преобразования}
\label{table:reg-res-no-text}
\end{table}

\begin{center}
\begin{table}
 \begin{tabular}{||p{3.8cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}||} 
\hline
& LSTM L=10 & LSTM L=30 & LinReg L=10 & LinReg L=30 & RFR L=10 & RFR L=30\\ \hline\hline
AE10 & 1.104 & 1.151 & 1.292 & 2.151 & 1.295 & 1.323\\ \hline
AE10+A & 1.084 & 1.058 & 1.025 & 1.924 & 0.898 & 0.925\\ \hline
AE10+R & 1.148 & 1.133 & 1.312 & 1.920 & 1.287 & 1.306\\ \hline
AE10+AR & 1.047 & 1.067 & 1.029 & 1.745 & 0.896 & 0.929\\ \hline
AE50 & 1.148 & 1.120 & 3.492 & 1.862 & 1.300 & 1.307\\ \hline
AE50+A & 1.046 & 1.068 & 3.082 & 1.810 & 0.899 & 0.918\\ \hline
AE50+R & 1.124 & 1.136 & 2.840 & 1.967 & 1.305 & 1.307\\ \hline
AE50+AR & 1.057 & 1.051 & 2.152 & 2.126 & 0.895 & 0.919\\ \hline
NMF10 & 1.171 & 1.068 & 1.241 & 2.921 & 1.171 & 1.187\\ \hline
NMF10+A & 1.077 & 1.059 & 0.973 & 2.280 & \textbf{0.894} & 0.933\\ \hline
NMF50 & 1.168 & 1.108 & 3.534 & 1.212 & 1.123 & 1.148\\ \hline
NMF50+A & 1.072 & 1.062 & 3.094 & 1.205 & 0.902 & 0.910\\ \hline
\end{tabular}
\caption{\label{table:reg-res} Результаты по метрике MASE для задачи регрессии c использованием текста и без лог-преобразования}
\end{table}
\end{center}


\begin{table}
\centering
\begin{tabular}{||p{3.8cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}||} 
\hline
& LSTM L=10 & LSTM L=30 & LinReg L=10 & LinReg L=30 & RFR L=10 & RFR L=30\\ \hline\hline
AE10 & 1.128 & 1.100 & 1.017 & 1.020 & 1.139 & 1.141\\ \hline
AE10+A & 1.054 & 1.014 & 1.028 & 1.729 & 0.848 & 0.875\\ \hline
AE50 & 1.059 & 1.035 & 1.127 & 3.075 & 1.073 & 1.105\\ \hline
AE50+A & 1.017 & 1.012 & 1.171 & 6.938 & 0.836 & 0.886\\ \hline
AE10+R & 1.105 & 1.068 & 1.046 & 1.087 & 1.135 & 1.151\\ \hline
AE10+R+A & 1.031 & 1.022 & 1.006 & 1.869 & \textbf{0.829} & 0.872\\ \hline
AE50+R & 1.052 & 0.979 & 1.141 & 5.021 & 1.107 & 1.116\\ \hline
AE50+R+A & 1.072 & 1.024 & 8.402 & 9.042 & 0.834 & 0.872\\ \hline
NMF10 & 1.055 & 1.088 & 1.108 & 1.263 & 1.010 & 1.047\\ \hline
NMF10+A & 1.025 & 1.032 & 1.008 & 1.582 & 0.862 & 0.898\\ \hline
NMF50 & 1.006 & 1.003 & 5.073 & 1.060 & 1.026 & 1.063\\ \hline
NMF50+A & 1.070 & 1.015 & 9.072 & 1.354 & 0.856 & 0.916\\ \hline
\end{tabular}
\caption{Результаты по метрике MASE для задачи регрессии c использованием лог-преобразования и без использования текста}
\label{table:reg-res-no-text-log}
\end{table}

\begin{center}
\begin{table}
 \begin{tabular}{||p{3.8cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}||} 
\hline
& LSTM L=10 & LSTM L=30 & LinReg L=10 & LinReg L=30 & RFR L=10 & RFR L=30\\ \hline\hline
AE10 & 1.057 & 1.051 & 1.216 & 5.461 & 1.149 & 1.172\\ \hline
AE10+A & 1.044 & 1.021 & 1.071 & 2.431 & 0.850 & 0.875\\ \hline
AE50 & 1.069 & 1.030 & 1.429 & 1.835 & 1.098 & 1.101\\ \hline
AE50+A & 1.047 & 1.024 & 1.283 & 2.097 & 0.859 & 0.869\\ \hline
AE10+R & 1.087 & 1.050 & 1.260 & 2.983 & 1.156 & 1.173\\ \hline
AE10+R+A & 1.041 & 1.030 & 1.082 & 4.846 & \textbf{0.843} & 0.868\\ \hline
AE50+R & 1.058 & 1.048 & 3.185 & 2.193 & 1.083 & 1.106\\ \hline
AE50+R+A & 1.035 & 1.029 & 9.062 & 1.089 & \textbf{0.843} & 0.891\\ \hline
NMF10 & 1.085 & 1.121 & 1.283 & 2.061 & 1.015 & 1.075\\ \hline
NMF10+A & 1.036 & 1.006 & 1.098 & 6.303 & 0.844 & 0.927\\ \hline
NMF50 & 1.114 & 1.175 & 5.817 & 1.112 & 1.056 & 1.060\\ \hline
NMF50+A & 1.047 & 1.028 & 3.428 & 3.692 & 0.861 & 0.914\\ \hline
\end{tabular}
\caption{\label{table:reg-res-log} Результаты по метрике MASE для задачи регрессии c использованием лог-преобразования и с использованием текста}
\end{table}
\end{center}

\begin{figure}
  \includegraphics[width=\linewidth]{images/reg_noaux.png}
  \caption{Пример работы модели регрессии без использования AUX признаков}
  \label{fig:rf_reg_noaux}
\end{figure}

\begin{figure}
  \includegraphics[width=\linewidth]{rf_reg_example.png}
  \caption{Пример работы модели регрессии с использованием AUX признаков}
  \label{fig:rf_reg_example}
\end{figure}


\subsubsection{Анализ полученных результатов}
В задаче классификации нейронные сети с LSTM-архитектурой оставляют остальные модели далеко позади, а добавление вспомогательных признаков 
(+A, +AR) позволяет улучшить качество прогноза на 10-40\%, в зависимости от типа модели. Это означает, что авторегрессионная компонента очень важна для точных прогнозов. Использование текста позволяет незначительно улучшить результаты (+1.5\%), но применимость текстовых признаков в целом зависит от типа модели. На Рис. \ref{fig:rf_reg_noaux} и \ref{fig:rf_reg_example} приведены примеры результатов работы модели регрессии без использования вспомогательных признаков и с их использованием соответственно.

Результаты в задаче регрессии схожи с результатами, описанными выше, но в задаче регрессии лучшей моделью оказался RandomForest Regressor, а не нейросеть LSTM. Как и в задаче классификации, вспомогательные признаки позволили значительно улучшить качество прогноза (до 30\%, в зависимости от типа модели).
В отличие от результатов задачи классификации, использование текста снижает точность прогноза на 1.5-2\%, это означает, что текстовая информация может быть полезна при решении одних задач и бесполезна или даже вредна при решении других задач.
Результаты регрессии с использованием логарифмического преобразования представлены в таблицах \ref{table:reg-res-no-text} и \ref{table:reg-res-log}. Использование такого преобразования позволило улучшить качество прогноза на 5-6\%.
